---
title: Facebook的公式如何助长愤怒和错误信息1/3
---
`西班牙巴塞罗那喜悦农场` [轉載自GNews](https://gnews.org/zh-hans/1620973/)

### **（第一部分）**

**编译：JennyBall**
![](https://assets.gnews.org/wp-content/uploads/2021/10/tempsnip74.png)图片来源：华盛顿邮报
Facebook 工程师赋予表情符号反应额外的价值，包括“生气”，将更多情绪化和挑衅性的内容推送到用户的新闻提要中。

五年前，除了标志性的“喜欢”竖起大拇指之外，Facebook 为用户提供了五种新的方式来对他们的新闻提要中的帖子做出反应：“爱”、“哈哈”、“哇”、“悲伤”和“愤怒”。

在幕后，**Facebook 对算法进行编程，该算法决定人们在新闻提要中看到什么，以使用反应表情符号作为信号，来推送更多情绪化和挑衅性内容**——包括可能让他们生气的内容。内部文件显示，从 2017 年开始，Facebook 的排名算法将表情符号反应的价值视为“喜欢”的五倍。**理论很简单：引发大量反应表情符号的帖子，往往会让用户更加参与，而保持用户参与是 Facebook 业务的关键。**

Facebook 自己的研究人员，很快就怀疑存在严重缺陷。支持“有争议”的帖子——包括那些让用户生气的帖子——可能会在不经意间打开“更多垃圾邮件/滥用/点击诱饵的大门”。一名姓名被删减的员工，在其中一份内部文件中写道。一位同事回答说：“有可能。”

事实证明，这一警告是有先见之明的。该公司的数据科学家在 2019 年证实，**引发愤怒反应表情符号的帖子极有可能包含错误信息、毒性和低质量新闻。**

这意味着， Facebook 三年来**系统地增强了其平台中一些最糟糕的部**分，使其在用户信息流中更加突出，并将其传播给更广泛的受众。算法推广的力量削弱了 Facebook 内容审核员和诚信团队的努力，他们正在与有毒和有害内容进行艰苦的战斗。

关于“愤怒”表情符号，的内部辩论及其影响的调查结果，揭示了构成 Facebook 新闻提要算法的，高度主观的人为判断——拜占庭机器学习软件，每次他们打开应用程序时，为数十亿人决定，他们将看到什么样的帖子 。审议结果在向证券交易委员会披露的信息中披露，并由举报人弗朗西丝·豪根（ Frances Haugen）的法律顾问以编辑形式提供给国会。编辑后的版本由包括《华盛顿邮报》在内的新闻机构联盟进行审查。

“愤怒和仇恨是在 Facebook 上发展的最简单方式，” 豪根周一对英国议会说。 在一些情况下，文件显示 Facebook 员工在其“诚信”团队中，举起了关于排名系统特定元素的人力成本的旗帜——高管们有时会注意这些警告，有时似乎置若罔闻。**员工对愤怒，在社会中的重要性进行了评估和辩论：一位员工写道，愤怒是“人类的核心情感”**，而另一位员工则指出，引发愤怒的帖子，可能对抗议腐败政权的运动至关重要。
![](https://assets.gnews.org/wp-content/uploads/2021/10/tempsnip75.png)
“扮演恶魔拥护者的快速问题：将愤怒反应比喜欢加强 5 倍，是否会导致新闻提要的争议内容比例高于令人愉快的内容？”
马萨诸塞州本特利大学的数学教授、《如何算法 创建和防止假新闻》一书的作者诺亚·吉安西拉库萨说，Facebook这样的算法依靠复杂、不透明的机器学习技术来生成其参与度预测，“听起来可能神秘而具有威胁性”。“但归根结底，有一个数字可以被预测——一个输出。人类正在决定这个数字是多少。”

Facebook 发言人丹尼·莱弗( Dani Lever )表示：“我们将继续努力了解，哪些内容会带来负面体验，从而减少其传播。例如，这包括具有不成比例的愤怒反应的内容。”

**愤怒反应的分量，只是 Facebook 工程师用来塑造全球最大社交网络上信息和对话流的众多杠杆之一**——**这一渠道已被证明：会影响从用户情绪到政治运动，再到暴行的方方面面。**

**Facebook ****如何塑造您的提要**

Facebook 考虑了许多因素——其中一些被加权计算得很多，一些计算得很少，一些计算为负——这些因素加起来就是，新闻提要算法为每个用户的每个帖子生成的一个分数，在你每次刷新的时候。该分数反过来用于对帖子进行排序，决定哪些出现在顶部，哪些出现在您可能永远看不到的位置。这个单一的包罗万象的评分系统， 被用来对世界上几乎每个国家，和 100 多种语言的大量人类互动进行分类和排序。

Facebook 没有公布其算法对不同类型参与的价值，更不用说它所说的 10,000 多个“信号”，它的软件可以在预测每个帖子产生这些参与形式的可能性时加以考虑。它经常提到害怕给怀有恶意的人一个剧本，来解释为什么它要保密内部运作。

文件显示，**Facebook 的杠杆依赖于大多数用户不会注意到的信号**，例如帖子产生了多少长评论，或者视频是直播还是录制，或者评论是以纯文本还是卡通头像进行的。它甚至考虑了每个帖子所需的计算负载和用户互联网信号的强度。**根据杠杆的不同，即使是微小的调整也会在整个网络中产生涟漪效应**，从而影响您提要中的新闻来源是否有信誉或粗略、政治与否，无论您是否看到了加入你更多真正的朋友，或来自 Facebook 想要加入你的群组的更多帖子，或者，如果你看到的东西可能会让你生气、厌烦或激励你。

除了对愤怒表情符号的争论之外，这些文件还显示 Facebook 员工正在努力解决有关公司价值观的棘手问题，并进行巧妙构建的分析。当他们发现算法正在加剧危害时，他们主张进行他们认为可能有帮助的调整。但这些提议有时被否决。

当提升，如表情符号的提升，与旨在限制潜在有害内容的“降低”或“降级”相冲突时，所有这些复杂的数学加起来，都会导致保护用户的问题。根据文件，平均帖子得分为几百。但在 2019 年，一位 Facebook 数据科学家发现，排名分数的高低是没有限制的。

**评论：**

**让我们跟随这篇分三部分的长文，看看科技网络大咖非死不可（Facebook），是如何左右了全世界人民的思想和话语权，以利于我们了解为什么文贵先生说：媒体比原子弹的威力大！也更加感恩我们的GTV， G news，Gettr为真不破的原则。一个人的判断决定他的一生，而作出判断的基础是信息的真伪。**

（文章仅代表作者观点，与GNEWS无关）

**参考资料：**[washingtonpost.com] [Five points for anger, one for a ‘like’: How Facebook’s formula fostered rage and misinformation](https://www.washingtonpost.com/technology/2021/10/26/facebook-angry-emoji-algorithm/?utm_campaign=wp_post_most&amp;utm_medium=email&amp;utm_source=newsletter&amp;wpisrc=nl_most&amp;carta-url=https%3A%2F%2Fs2.washingtonpost.com%2Fcar-ln-tr%2F3519683%2F61782ca69d2fda9d412545d8%2F5e2dde419bbc0f6326309bfd%2F9%2F74%2F61782ca69d2fda9d412545d8)

相关链接：[Facebook的公式如何助长愤怒和错误信息2/3](https://gnews.org/zh-hans/1620941/)
 Facebook的公式如何助长愤怒和错误信息3/3

* * *

***审核：文乐
校对：信心满满
发布：信心满满***

![](https://assets.gnews.org/wp-content/uploads/2021/10/GNEWS_CH.-1-3-1.jpeg)

 

免责声明：本文内容仅代表作者个人观点，平台不承担任何法律风险。

- [ROL Foundation](https://rolfoundation.org/)
- [ROL Society](https://rolsociety.org/)
- [Terms of use](https://gnews.org/terms-of-use-3/)
- [Privacy Policy](https://gnews.org/privacy-policy/)
